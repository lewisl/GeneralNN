# Some experiments training with dropout

train_nn("digits60000by784.mat",30,[200,200],reg="L2",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.5,.8]);
Training time: 220.239794572 seconds
Fraction correct labels predicted training: 0.9912666666666666
Final cost training: 0.049638668796668645
Fraction correct labels predicted test: 0.9798
Final cost test: 0.13536817978748747
Test data accuracy in final 10 iterations:
0.978 : 0.979 : 0.980 : 0.979 : 0.979 : 0.979 : 0.978 : 0.978 : 0.979 : 0.980 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",30,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.5,.8]);
Training time: 229.669913241 seconds
Fraction correct labels predicted training: 0.9904
Final cost training: 0.05338128366771617
Fraction correct labels predicted test: 0.979
Final cost test: 0.13051026183040532
Test data accuracy in final 10 iterations:
0.979 : 0.979 : 0.978 : 0.978 : 0.980 : 0.978 : 0.979 : 0.978 : 0.978 : 0.979 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",30,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.8,.6]);
Training time: 233.641356536 seconds
Fraction correct labels predicted training: 0.9946
Final cost training: 0.09530716462850518
Fraction correct labels predicted test: 0.9806
Final cost test: 0.7438897137191901
Test data accuracy in final 10 iterations:
0.981 : 0.978 : 0.979 : 0.980 : 0.980 : 0.981 : 0.981 : 0.980 : 0.979 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",30,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.7,.5]);
Training time: 228.364985403 seconds
Fraction correct labels predicted training: 0.9904833333333334
Final cost training: 1.017786199337508
Fraction correct labels predicted test: 0.9788
Final cost test: 3.068922921844729
Test data accuracy in final 10 iterations:
0.979 : 0.977 : 0.979 : 0.978 : 0.979 : 0.979 : 0.982 : 0.979 : 0.979 : 0.979 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",30,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.5]);
Training time: 240.504804495 seconds
Fraction correct labels predicted training: 0.9930333333333333
Final cost training: 1.041023479423465
Fraction correct labels predicted test: 0.9774
Final cost test: 3.9597997018480187
Test data accuracy in final 10 iterations:
0.980 : 0.978 : 0.975 : 0.980 : 0.979 : 0.978 : 0.981 : 0.976 : 0.979 : 0.977 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.5]);
Training time: 152.650883274 seconds
Fraction correct labels predicted training: 0.9935666666666667
Final cost training: 0.2578829596936337
Fraction correct labels predicted test: 0.9779
Final cost test: 1.7321110644284976
Test data accuracy in final 10 iterations:
0.978 : 0.975 : 0.980 : 0.979 : 0.979 : 0.977 : 0.975 : 0.976 : 0.978 : 0.978 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.8,.4]);
Training time: 167.694005542 seconds
Fraction correct labels predicted training: 0.9876333333333334
Final cost training: 2.6804928231737284
Fraction correct labels predicted test: 0.9757
Final cost test: 5.4374657601700545
Test data accuracy in final 10 iterations:
0.972 : 0.975 : 0.977 : 0.977 : 0.975 : 0.976 : 0.974 : 0.975 : 0.977 : 0.976 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.6);
ERROR: syntax: missing separator in array expression

julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.6]);
Training time: 165.591377169 seconds
Fraction correct labels predicted training: 0.9953333333333333
Final cost training: 0.055448318366697565
Fraction correct labels predicted test: 0.981
Final cost test: 0.3776509728786523
Test data accuracy in final 10 iterations:
0.980 : 0.978 : 0.981 : 0.980 : 0.980 : 0.980 : 0.981 : 0.979 : 0.982 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 160.369492108 seconds
Fraction correct labels predicted training: 0.9952
Final cost training: 0.035645503804922145
Fraction correct labels predicted test: 0.9806
Final cost test: 0.21848354012664506
Test data accuracy in final 10 iterations:
0.977 : 0.979 : 0.979 : 0.982 : 0.982 : 0.983 : 0.982 : 0.982 : 0.979 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.350,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 156.296978804 seconds
Fraction correct labels predicted training: 0.9951166666666666
Final cost training: 0.030479271280832564
Fraction correct labels predicted test: 0.9798
Final cost test: 0.20086250137252606
Test data accuracy in final 10 iterations:
0.980 : 0.981 : 0.978 : 0.980 : 0.982 : 0.982 : 0.981 : 0.981 : 0.981 : 0.980 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 154.379862171 seconds
Fraction correct labels predicted training: 0.9958166666666667
Final cost training: 0.03421840580839482
Fraction correct labels predicted test: 0.9816
Final cost test: 0.2535815969989636
Test data accuracy in final 10 iterations:
0.981 : 0.982 : 0.981 : 0.982 : 0.981 : 0.981 : 0.980 : 0.984 : 0.982 : 0.982 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.5,.5]);
Training time: 159.890429903 seconds
Fraction correct labels predicted training: 0.9810666666666666
Final cost training: 0.3053905610400063
Fraction correct labels predicted test: 0.9722
Final cost test: 0.601020303554036
Test data accuracy in final 10 iterations:
0.970 : 0.968 : 0.974 : 0.969 : 0.970 : 0.969 : 0.971 : 0.973 : 0.973 : 0.972 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",40,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.5,.5]);
Training time: 331.110197646 seconds
Fraction correct labels predicted training: 0.9839666666666667
Final cost training: 1.9318391895356501
Fraction correct labels predicted test: 0.9758
Final cost test: 3.2441301940180507
Test data accuracy in final 10 iterations:
0.974 : 0.974 : 0.975 : 0.974 : 0.974 : 0.973 : 0.975 : 0.975 : 0.974 : 0.976 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",40,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.5]);
Training time: 354.975587652 seconds
Fraction correct labels predicted training: 0.9952
Final cost training: 1.085932964650244
Fraction correct labels predicted test: 0.9801
Final cost test: 4.507855211110921
Test data accuracy in final 10 iterations:
0.980 : 0.980 : 0.982 : 0.979 : 0.980 : 0.979 : 0.979 : 0.980 : 0.980 : 0.980 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",40,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 320.257973638 seconds
Fraction correct labels predicted training: 0.9972166666666666
Final cost training: 0.04009597889052355
Fraction correct labels predicted test: 0.9814
Final cost test: 0.7369453959558758
Test data accuracy in final 10 iterations:
0.981 : 0.983 : 0.981 : 0.981 : 0.980 : 0.982 : 0.983 : 0.982 : 0.981 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",30,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 241.275588044 seconds
Fraction correct labels predicted training: 0.9958333333333333
Final cost training: 0.04272028355295634
Fraction correct labels predicted test: 0.9798
Final cost test: 0.42528061869229444
Test data accuracy in final 10 iterations:
0.982 : 0.982 : 0.980 : 0.981 : 0.982 : 0.982 : 0.977 : 0.981 : 0.980 : 0.980 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",25,[200,200],reg="",lambda=.000005,alpha=0.60,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 224.447492846 seconds
Fraction correct labels predicted training: 0.9957166666666667
Final cost training: 0.04152595610648278
Fraction correct labels predicted test: 0.9819
Final cost test: 0.32851400193830527
Test data accuracy in final 10 iterations:
0.981 : 0.980 : 0.984 : 0.982 : 0.982 : 0.982 : 0.982 : 0.980 : 0.981 : 0.982 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 194.173070793 seconds
Fraction correct labels predicted training: 0.9948666666666667
Final cost training: 0.05111806537524267
Fraction correct labels predicted test: 0.9794
Final cost test: 0.3807730206563907
Test data accuracy in final 10 iterations:
0.981 : 0.977 : 0.982 : 0.981 : 0.978 : 0.979 : 0.982 : 0.980 : 0.981 : 0.979 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.7,.7]);
Training time: 182.442029756 seconds
Fraction correct labels predicted training: 0.99165
Final cost training: 0.059070101538397
Fraction correct labels predicted test: 0.9798
Final cost test: 0.2373685654616061
Test data accuracy in final 10 iterations:
0.978 : 0.975 : 0.979 : 0.979 : 0.978 : 0.979 : 0.980 : 0.979 : 0.979 : 0.980 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.7]);
Training time: 166.613244924 seconds
Fraction correct labels predicted training: 0.9948666666666667
Final cost training: 0.05111806537524267
Fraction correct labels predicted test: 0.9794
Final cost test: 0.3807730206563907
Test data accuracy in final 10 iterations:
0.981 : 0.977 : 0.982 : 0.981 : 0.978 : 0.979 : 0.982 : 0.980 : 0.981 : 0.979 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=0.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9]);
Training time: 181.762817331 seconds
Fraction correct labels predicted training: 0.99705
Final cost training: 0.017833594438738633
Fraction correct labels predicted test: 0.9829
Final cost test: 0.15635379854148881
Test data accuracy in final 10 iterations:
0.977 : 0.979 : 0.980 : 0.982 : 0.981 : 0.982 : 0.977 : 0.981 : 0.981 : 0.983 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=1.00,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],do_learn_decay=true,[.8,3.0]);
ERROR: MethodError: no method matching train_nn(::String, ::Int64, ::Array{Int64,1}, ::Array{Float64,1}; reg="", lambda=5.0e-6, alpha=1.0, do_batch_norm=true, plots=String["Learning", "Training", "Test"], mb_size=50, units="relu", opt="adam", dropout=true, droplim=[0.9, 0.9], do_learn_decay=true)
Closest candidates are:
  train_nn(::String, ::Int64, ::Array{Int64,1}; alpha, mb_size, lambda, classify, norm_mode, opt, opt_params, units, do_batch_norm, reg, dropout, droplim, plots, learn_decay) at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:356 got unsupported keyword argument "do_learn_decay"

julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=1.00,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);
Training time: 154.769491708 seconds
Fraction correct labels predicted training: 0.9969833333333333
Final cost training: 0.018409443080897387
Fraction correct labels predicted test: 0.9814
Final cost test: 0.19152777297104723
Test data accuracy in final 10 iterations:
0.981 : 0.978 : 0.981 : 0.981 : 0.981 : 0.982 : 0.983 : 0.981 : 0.980 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=1.00,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,2.0]);


 **** at 10 stepping down learning rate to 0.8
Training time: 155.452270524 seconds
Fraction correct labels predicted training: 0.9976333333333334
Final cost training: 0.014119754124088594
Fraction correct labels predicted test: 0.9829
Final cost test: 0.1733306455166827
Test data accuracy in final 10 iterations:
0.982 : 0.980 : 0.982 : 0.983 : 0.984 : 0.982 : 0.983 : 0.982 : 0.983 : 0.983 : 
Press enter to close plot window...

train_nn("digits60000by784.mat",21,[200,200],reg="",lambda=.000005,alpha=1.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 7 stepping down learning rate to 1.2000000000000002


 **** at 14 stepping down learning rate to 0.9600000000000002
Training time: 206.155036839 seconds
Fraction correct labels predicted training: 0.997
Final cost training: 0.01789507197682112
Fraction correct labels predicted test: 0.9812
Final cost test: 0.21163352733193352
Test data accuracy in final 10 iterations:
0.981 : 0.982 : 0.983 : 0.982 : 0.984 : 0.984 : 0.984 : 0.984 : 0.984 : 0.981 : 

Last login: Sun May 27 14:15:46 on ttys000
MacBook-Pro:nn by hand lewis$ julia
               _
   _       _ _(_)_     |  A fresh approach to technical computing
  (_)     | (_) (_)    |  Documentation: https://docs.julialang.org
   _ _   _| |_  __ _   |  Type "?help" for help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 0.6.2 (2017-12-13 18:08 UTC)
 _/ |\__'_|_|_|\__'_|  |  Official http://julialang.org/ release
|__/                   |  x86_64-apple-darwin14.5.0

julia> using Revise

julia> include("GeneralNN.jl")
GeneralNN

julia> Revise.track("GeneralNN.jl")

julia> using GeneralNN

julia> train_nn("digits60000by784.mat",21,[200,200],reg="",lambda=.000005,alpha=1.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 7 stepping down learning rate to 1.2000000000000002


 **** at 14 stepping down learning rate to 0.9600000000000002
Training time: 239.82163737 seconds
Fraction correct labels predicted training: 0.997
Final cost training: 0.01789507197682112
Fraction correct labels predicted test: 0.9812
Final cost test: 0.21163352733193352
Test data accuracy in final 10 iterations:
0.981 : 0.982 : 0.983 : 0.982 : 0.984 : 0.984 : 0.984 : 0.984 : 0.984 : 0.981 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",18,[200,200],reg="",lambda=.000005,alpha=1.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,2.0]);
WARNING: Method definition run_training(String, Int64, Array{Int64, 1}) in module GeneralNN at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:480 overwritten at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:480.
WARNING: Method definition #run_training(Array{Any, 1}, typeof(GeneralNN.run_training), String, Int64, Array{Int64, 1}) in module GeneralNN overwritten.


 **** at 9 stepping down learning rate to 1.4400000000000002
Training time: 237.773413957 seconds
Fraction correct labels predicted training: 0.9958166666666667
Final cost training: 0.026741615892462545
Fraction correct labels predicted test: 0.9809
Final cost test: 0.21083764417098932
Test data accuracy in final 10 iterations:
0.979 : 0.982 : 0.981 : 0.981 : 0.980 : 0.980 : 0.981 : 0.980 : 0.979 : 0.981 : 
Press enter to close plot window...


julia> 20/3
WARNING: Method definition step_lrn_decay!(Any, Any) in module GeneralNN at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191 overwritten at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191.
6.666666666666667

julia> Int(3.0)
3

julia> int(3.1)
ERROR: UndefVarError: int not defined

julia> Int(2.1)
ERROR: InexactError()
Stacktrace:
 [1] convert(::Type{Int64}, ::Float64) at ./float.jl:679
 [2] Int64(::Float64) at ./sysimg.jl:77

julia> 20/3.0
6.666666666666667

julia> floor(20/3)
WARNING: Method definition step_lrn_decay!(Any, Any) in module GeneralNN at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191 overwritten at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191.
6.0

julia> rem(6,6.0)
0.0

julia> rem(0,6)
0

julia> train_nn("digits60000by784.mat",18,[80,80],reg="",lambda=.000005,alpha=1.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,2.0]);
WARNING: Method definition step_lrn_decay!(Any, Any) in module GeneralNN at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191 overwritten at /Users/lewis/Dropbox/Online Coursework/ML Independent explorations/nn by hand/GeneralNN.jl:1191.


 **** at 9 stepping down learning rate to 1.4400000000000002
Training time: 59.967088653 seconds
Fraction correct labels predicted training: 0.99255
Final cost training: 0.04899374223559486
Fraction correct labels predicted test: 0.9778
Final cost test: 0.20625222894613346
Test data accuracy in final 10 iterations:
0.976 : 0.976 : 0.978 : 0.977 : 0.978 : 0.978 : 0.976 : 0.979 : 0.975 : 0.978 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[80,80],reg="",lambda=.000005,alpha=1.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 6 stepping down learning rate to 1.4400000000000002


 **** at 12 stepping down learning rate to 1.1520000000000001
Training time: 66.69484935 seconds
Fraction correct labels predicted training: 0.99255
Final cost training: 0.053265440119169984
Fraction correct labels predicted test: 0.9786
Final cost test: 0.22096731952705037
Test data accuracy in final 10 iterations:
0.977 : 0.979 : 0.977 : 0.978 : 0.978 : 0.980 : 0.978 : 0.978 : 0.981 : 0.979 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=1.80,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 6 stepping down learning rate to 1.4400000000000002


 **** at 12 stepping down learning rate to 1.1520000000000001
Training time: 264.228284023 seconds
Fraction correct labels predicted training: 0.9972666666666666
Final cost training: 0.018234323006297338
Fraction correct labels predicted test: 0.9815
Final cost test: 0.20747522164257085
Test data accuracy in final 10 iterations:
0.979 : 0.980 : 0.983 : 0.980 : 0.984 : 0.981 : 0.978 : 0.982 : 0.980 : 0.982 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",20,[200,200],reg="",lambda=.000005,alpha=1.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 6 stepping down learning rate to 1.2000000000000002


 **** at 12 stepping down learning rate to 0.9600000000000002
Training time: 203.782543874 seconds
Fraction correct labels predicted training: 0.9973
Final cost training: 0.01628772991851464
Fraction correct labels predicted test: 0.9828
Final cost test: 0.1756588159233208
Test data accuracy in final 10 iterations:
0.981 : 0.981 : 0.983 : 0.983 : 0.983 : 0.984 : 0.982 : 0.984 : 0.984 : 0.983 : 
Press enter to close plot window...


julia> train_nn("digits60000by784.mat",19,[200,200],reg="",lambda=.000005,alpha=1.50,do_batch_norm=true,plots=["Learning","Training","Test"],mb_size=50,units="relu",opt="adam",dropout=true,droplim=[.9,.9],learn_decay=[.8,3.0]);


 **** at 6 stepping down learning rate to 1.2000000000000002


 **** at 12 stepping down learning rate to 0.9600000000000002
Training time: 201.710253459 seconds
Fraction correct labels predicted training: 0.9973666666666666
Final cost training: 0.016248690476649917
Fraction correct labels predicted test: 0.9837
Final cost test: 0.16550443888419472
Test data accuracy in final 10 iterations:
0.982 : 0.981 : 0.981 : 0.983 : 0.983 : 0.983 : 0.984 : 0.982 : 0.984 : 0.984 :